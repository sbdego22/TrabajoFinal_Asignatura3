---
title: "Grupo 14_Trabajo_Final_Asignatura 3"
author: "Integrantes: Mercedes de la Torre Fuentes_Diego Alonso Solano Bolaños_Kattia Zúñiga Acosta_Ricardo Mir de Francia_Jacob Warris"
date: "2024-12-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(GGally)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(mltools)
library(e1071)
library (DMwR2)
library (ROCR)
library (pROC)
```
## **1.Analisis Exploratorio del Conjunto Datos <br><br>**
<div style="text-align: justify"> 

### **Introducción <br><br>**
Nuestro conjunto de datos inicial contiene 2111 observaciones y 18 variables (without any NA values), obtenidas inicialmente mediante una encuesta en línea y ampliadas después con datos sintéticos. Se preveía utilizar los datos para investigar qué factores están asociados al sobrepeso y la obesidad.<br>

```{r}
library(readr)
obesity_data_raw = read.csv("./data/ObesityDataSet_raw_and_data_sinthetic.csv", header = T, sep = ",")
head(obesity_data_raw)
tail(obesity_data_raw)
colSums(is.na(obesity_data_raw))
```

El objetivo de esta sección es explorar los datos disponibles en el conjunto de datos. A continuación, se realizarán las transformaciones necesarias para poder seguir trabajando con los datos más adelante.<br>

Para facilitar este segundo objetivo, ya hemos creado un segundo marco de datos "obesity_data_preprocessed": la idea es transformar el conjunto de datos inicial (denominado «obesity_data_raw») en este conjunto de datos preprocesado.<br>

```{r}
  obesity_data_preprocessed = obesity_data_raw
```

#### **1.1 Gender**<br><br>

Es una variable binaria que indica el género del/de la encuestado/-a.<br>

```{r}
library(plotrix)
table(as.factor(obesity_data_raw$Gender))
pie3D(table(as.factor(obesity_data_raw$Gender)), main = "Proporción de sexos", col = c("thistle 1", "light cyan"), border = "lightgrey", labels = c("Female (n = 1043)", "Male (n = 1068)"), labelcex = 0.75)
```

Toma el valor 'female' o 'male', que, obviamente son valores válidos. No hay nigún valor estraño o faltante.<br>

Además, constatamos que el conjunto de datos contiene una proporción entre hombres y mujeres encuestados bastante equitativa - es decir, hay 25 hombres más que mujeres, lo que supone una diferencia de (25 / 1043) * 100 ≈ 2.4%.<br>

Dicha equivalencia es especialmente importante cuando se trata de cuestiones médicas - como son el sobrepeso y el obesitas - considerando que el funcionamiento del cuerpo de una persona estùa en gran medida relacionado con su sexo.<br>

#### **Transformaciones** <br><br>
Para poder trabajar mejor con esta variable, aplicamos *label encoding*, dejando dos valores numéricos al final:<br>

* 0 - Female<br>
* 1 - Male<br>

```{r}
  obesity_data_preprocessed$Gender = as.integer(ifelse(obesity_data_preprocessed$Gender == 'Female', 0, 1))
```


#### **1.2 Age**<br><br>
Se trata de una variable discreta ordinal que indica la edad de/ de la encuestado, en años.<br>

table(obesity_data_raw$Age)<br>
  
Observamos que unos pocos valores distinctos de age son números enteros que tienen una frecuencia altas, mientras muchos valores distinctos son decimales con una frequencia baja.
Probablemente, eso es resultado del hecho que parte de los datos son sintetizados, y no provienen de una encuesta. Es decir: son calculados por un algortimo.<br>

Otra observación importante es que el conjunto de datos no está nada diversificada por edades - posiblemente debido al medio en el que se publicó esta encuesta (en linea). Un 82 porciento tiene menos que 30 años; un 97 porciento tiene menos que 40. El encuestado con mayor edad tiene 61 años.<br>

Esto significa que, basándose en este conjunto de datos, probablemente no sea posible hacer afirmaciones sobre toda la población - como mucho sobre aquella parte cuya edad está fuertemente representada en nuestra muestra.<br>

```{r}
print(round(cumsum(prop.table(table(round(obesity_data_raw$Age)))*100)))
barplot(round(cumsum(prop.table(table(round(obesity_data_raw$Age)))*100)), col = "light grey", border = "light grey", main = "Frequencia relativa acumulada de la variable Age", xlab = "Age", ylab ="Frecuencia relativa acumulada")
```
#### **Transformaciónes**<br>
Redondeamos los valores de la variable Age a números enteros; después la definimos como integer.<br>
```{r}
obesity_data_preprocessed$Age = as.integer(round(obesity_data_preprocessed$Age))
```

#### **1.3 Height**<br>
Una variable continua que indica la altura del/de la encuestado/-a, en metros. Podía ser un buen predictor de la obesidad - partiendo de la idea que las personas de estatura más baja requieren, en general, menos calorías que las personas altas, y entonces tienen más riesgo de hiperalimentarse.<br>

```{r}
table(round(obesity_data_raw$Height, digits = 2))
hist(obesity_data_raw$Height, main="Histograma de la variable Height", xlab="Height",ylab="densidad", col="light grey", border = "white", freq = FALSE, ylim = c(0,4))
```

El conjunto de datos cubre alturas entre 1.45 m y 1.98 m, con más observaciónes alrededor del 1.70 m. Todos los valores parecen válidos, aunque hay que observar que no podemos asumir una distribución normal.<br>

```{r}
shapiro.test(obesity_data_raw$Height)
# p < 0.05 - no podemos asumir la distribción normal.
```

##### **Transformaciones**<br>
Redondeamos los valores de Heigt a 2 decimales.<br>

```{r}
obesity_data_preprocessed$Height = round(obesity_data_preprocessed$Height, digits = 2)
```


#### **1.4. Weight**<br>
Una variable continua que indica el peso del/de la encuestado/-a, en kilos. Por razónes obvios, se espera que este valor prediga bien el sobrepeso y la obesidad - si sube el peso, suberá también la probabilidad de sobrepeso u obesidad.<br>

```{r}
table(round(obesity_data_raw$Weight))
hist(round(obesity_data_raw$Weight), main="Histograma de la variable Weight", xlab="Weight",ylab="densidad", col="light grey", border = "white", freq = FALSE, ylim = c(0,0.02))
```

El conjunto de datos cubre pesos entre 39 kg y 173; todos los valores parecen válidos.<br>


##### Transformaciones<br>
Redondeamos los valores de Weight a números enteros.<br>

```{r}
obesity_data_preprocessed$Height = as.integer(round(obesity_data_preprocessed$Height, digits = 2))
```


#### **1.5. BMI**<br>
Es una variable continua que indica el BMI (Body Mass Index - peso/altura^2). No está presente en el conjunto de datos original; calculada a partir de la altura y el peso de cada encuestado/-a incluido en dicho conjunto de datos, de la manera espcificada abajo.<br>
```{r}
obesity_data_preprocessed$BMI = obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2
```

```{r}
table(round(obesity_data_preprocessed$BMI))
hist(obesity_data_preprocessed$BMI, main="Histograma de la variable BMI", xlab="BMI",ylab="densidad", col="light grey", border = "white", freq = FALSE, ylim = c(0,0.02))
```
El BMI expresa la relación entre la altura y el peso de una persona, indicando así hasta qué punto la persona en cuestión tiene un peso saludable - vease también el apartado '7. Weight_Class_WHO'. En otras palabras, debería existir una fuerte relación positiva entre el BMI de un encuestado, y la clase de peso 'NObeyesdad' a la que se asigna esa persona (véase el apartado siguiente).<br>

#### **1.6. NObeyesdad / Weight_Class_Mendoza_De_La_Hoz**<br>
Una variable categórica nominal que clasifica los encuestados/-as según grado de peso saludable, como presentado en *Mendoza, Fabio & De la Hoz Manotas, Alexis. (2019). Dataset for estimation of obesity levels based on eating habits and physical condition in individuals from Colombia, Peru and Mexico. Data in Brief. 25. 104344. 10.1016/j.dib.2019.104344*.<br>

Clasifica a los encuestados en una de las siguientes categorías:<br>

Valores disponibles:<br>
 * Insufficient_weight<br>
 * Normal_weight<br>
 * Overweight_level_I<br>
 * Overweight_level_II<br>
 * Obesity_type_I<br>
 * Obesity_type_II<br>
 * Obesity_type_III<br>

Tenga en cuenta que la publicación mencionada no especifica con precisión cómo se asigna una persona determinada a una u otra categoría de peso.<br>

Casi con toda seguridad, la relación entre peso y longitud es importante en la clasificación, pero observar los valores mínimos y máximos abajo, hay que constatar que las clases tienen cierto solapamiento en cuanto al BMI. Eso puede ser resulto de la generación de datos sinteticos; también puede significar que la clasificación la clasificación tiene en cuenta otros valores, además del BMI.<br>

```{r}
bmi_insufficient_weight = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad =="Insufficient_Weight"]
bmi_normal_weight = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Normal_Weight"]
bmi_overweight_level_I = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Overweight_Level_I"]
bmi_overweight_level_II = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Overweight_Level_II"]
bmi_obesity_type_I = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Obesity_Type_I"]
bmi_obesity_type_II = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Obesity_Type_II"]
bmi_obesity_type_III = obesity_data_raw$bmi[obesity_data_raw$NObeyesdad == "Obesity_Type_III"]
  
summary(bmi_insufficient_weight)
summary(bmi_normal_weight)
summary(bmi_overweight_level_I)
summary(bmi_overweight_level_II)
summary(bmi_obesity_type_I)
summary(bmi_obesity_type_II)
summary(bmi_obesity_type_III)

rm(bmi_insufficient_weight)
rm(bmi_normal_weight)
rm(bmi_overweight_level_I)
rm(bmi_overweight_level_II)
rm(bmi_obesity_type_I)
rm(bmi_obesity_type_II)
rm(bmi_obesity_type_III)
```

```{r}
table(obesity_data_raw$NObeyesdad)
barplot(table(obesity_data_raw$NObeyesdad), main="Diagrama de barras de la variable NObeyesdad", col="light grey", border = "white", las=2, cex.names = 0.5)
```
#### **Transformaciones**<br>
Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

 * 0 - Insufficient_weight<br>
 * 1 - Normal_weight<br>
 * 2 - Overweight_level_I<br>
 * 3 - Overweight_level_II<br>
 * 4 - Obesity_type_I<br>
 * 5 - Obesity_type_II<br>
 * 6 - Obesity_type_III<br>

Además, cambiamos el nombre de la variable - para que refleje mejor la carga de la variable, para que tenga una capitalización en linéa con las otras variables, y para que sea más distingida de la otra variable que compone una categorización de peso (Weight_CLass_WHO, veáse a continuación).<br>

La nombramos 'Weight_Class_Mendoza_De_La_Hoz'.<br>

#### **1.7 Weight_Class_WHO** <br>
Es variable discreta ordinal que clasifica los encuestados/-as según grado de peso saludable, según la normativa de la Organización Mundial de la Salud (OMS, WHO en inglés).<br>

Es un dato no presente en el conjunto de datos original, calculada a partir del BMI de cada encuestado/-a de acuerdo con la siguiente asignación:<br>

 * 0 - Infrapeso (BMI bajo 18.5)<br>
 * 1 - Normal (BMI entre 18.5 y 24.9)<br>
 * 2 - Sobrepeso (BMI entre 25.0 y 29.9)<br>
 * 3 - Obesidad I (BMI entre 30.0 y 34.9)<br>
 * 4 - Obesidad II (BMI entry 35.0 y 39.9)<br>
 * 5 - Obesidad III (BMI superior a 40)<br>
 
```{r}
obesity_data_preprocessed$Weight_Class_WHO = as.integer(
    ifelse(
    obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2 > 40, 5, ifelse(
      obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2 >= 35, 4, ifelse(
        obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2 >= 30, 3, ifelse(
          obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2 >= 25, 2, ifelse(
            obesity_data_preprocessed$Weight/obesity_data_preprocessed$Height^2 >= 18.5, 1, 0
          )
        )
      )
    )
  )
)
```


```{r}
table(obesity_data_preprocessed$Weight_Class_WHO)
barplot(table(obesity_data_preprocessed$Weight_Class_WHO), main="Diagrama de barras de la variable Weight_Class_WHO", col="light grey", border = "white")
```

#### **1.8. family_history_with_overweight / Overweight_Family** <br>
Es una variable binaria que indica si tiene familiares con sobrepeso el/la encuestado/-a.<br>

Podía ser una variable miu potente en predicir la probabilidad de sobrepeso en una persona; sin embargo, un interrogatorio más específico podría haber dado lugar a un predictor más potente - por ejemplo, si alguien tiene padres o hermanos con sobrepeso. 'Familia' es un un concepto muy amplio, y sin marcas claras - algo que se ve reflejado en el hecho que una gran mayoría de los encuestados (casí 82 %) sí tiene algún miembro de familia con sobrepeso.<br>

```{r}
table(obesity_data_raw$family_history_with_overweight)

pie3D(table(as.factor(obesity_data_raw$family_history_with_overweight)), main = "Proporción de encuestados con/sin familia con sobrepeso", col = c("white", "light grey"), border = "light grey", labels = c("no (n = 385)", "yes (n = 1726)"))
```


#### **Transformaciones**<br>
Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

 * 0 - no<br>
 * 1 - yes<br>

Además, cambiamos el nombre de la variable - para que que tenga una capitalización en conformidad con las otras variables; en el proceso, también hacemos el nombre un poco más corto. La nombramos 'Overweight_Family'.<br>

```{r}
obesity_data_preprocessed$Overweight_Family = as.integer(ifelse(obesity_data_preprocessed$family_history_with_overweight == "no", 0, 1))
```


#### **1.9 FAVC / High_Caloric_Consumption**<br>
Se trata de variable binaria que indica si el/la encuestado/-a consume comida rica en calorías regularmente.<br>

```{r}
table(as.factor(obesity_data_raw$FAVC))

pie3D(table(as.factor(obesity_data_raw$FAVC)), main = "Proporción de encuestados que sí / no consume comida rica en calorías regularmente", col = c("white", "light grey"), border = "light grey", labels = c("no (n = 245)", "yes (n = 1866)"))
```

Hacemos la misma observación que en relación con la variable anterior: podía ser muy potente para predicir el sobrepeso - obviamente - pero la formulación poca definida de la pregunta probablemente ha quitado algo de esa potencia. Más especifífico: qué quiere decir 'regularmente'?<br>

Efectivamente, vemos que de nuevo una gran mayoría de los encuestados (más que 88%) ha respondido de manera confirmativa.<br>

#### **Transformacione**s
Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

* 0 - no<br>
* 1 - yes<br>

Además, cambiamos el nombre de la variable - para que que tenga una capitalización en conformidad con las otras variables, y para evitar abreviacióne potencialmente confusas. La nombramos 'High_Caloric_Consumption'.<br>

```{r}
obesity_data_preprocessed$High_Caloric_Consumption = as.integer(ifelse(obesity_data_preprocessed$FAVC == "no", 0, 1))
```


#### **1.10 FCVC / Vegetable_Consumption**<br>
Se trata variable categórica ordinal que indica como de frequente el/la encuestado/-a consume verduras, según la siguiente asignación.<br>

* 1 - Nunca<br>
* 2 - De vez en cuando<br>
* 3 - Siempre<br>

```{r}
table(round(obesity_data_raw$FCVC))

barplot(table(round(obesity_data_raw$FCVC)), main="Diagrama de barras de la variable FCVC", col="light grey", border = "white")
```

Podía ser un buen predictor para el sobrepeso de una persona, especialmente combinado con otras variables que indican una dieta sana (por ejemplo, la consomación de agua, no consumir entre comidas principales).<br>

#### **Transformaciones**<br>
En el conjunto de datos original, la variable FCVC tome valores descimales, algo aue no es conforme con el hecho que es una variable discreta. Por eso, vamos a redondearla. Después, para guardar la conformidad en el conjunto de datos, la transformamos de forma que el valor más bajo sea 0. La asinación nueva será, entonces:<br>

* 0 - Nunca <br>
* 1 - De vez en cuando <br>
* 2 - Siempre<br>

Además le nombramos 'Vegetable_Consumption', para evitar abreviaciónes potencialmente confusas.<br>

```{r}
obesity_data_preprocessed$Vegetable_Consumption = as.integer(
  round(
    ifelse(
      obesity_data_preprocessed$FCVC == 1, 0, ifelse(
      obesity_data_preprocessed$FCVC == 2, 1, 2
      )
    )
  )
)
```


#### **1.11. NCP / Main_Meals**<br>
Se trata de una variable categorica ordinal que indica cuantas comidas principales come el/la encuestado/-a por día.<br>

La descripción del conjunto de datos indica, que el encuesto ofreció las siguientes respuestas a la pregunta, cuántas comidas principales el/la encuestado/-a consumepor día.<br>

* 1 o 2<br>
* 3<br>
* Más que 3<br>

Sin embargo, cuando miramos los valores presentes en el conjunto de datos, encontramos valores hasta 4. Además, el hecho que el valor más frequente es '3' sugiere que, en realidad, esa variable indica la cantidad de comidas principales por día (desayuno - almuerzo - cena).<br>
```{r}
table(round(obesity_data_raw$NCP))

barplot(table(round(obesity_data_raw$NCP)), main="Diagrama de barras de la variable NCP", col="light grey", border = "white")
```
No esperamos una relación fuerte entre cantidad de comidas principales, y el sobrepeso. Quizá exista una relación indirecta: las personas con patrones alimentarios menos estructurados -es decir, las que hacen menos comidas principales- pueden picar más, lo que aumentaría el riesgo de obesidad.<br>

#### **Transformaciones**
Visto que se trata de una variable discreta, redondeamos sus valores. Adeḿas cambiamos su nombre a 'Main_Meals', para evitar abreviaciónes potencialmente confusas.<br>

```{r}
obesity_data_preprocessed$Main_Meals = as.integer(round(obesity_data_preprocessed$NCP))
```

#### **1.12. CAEC / Between_Meals**<br>
Es una variable categorica ordinal que indica como de frequente el/la encuestado/-a come entre comidas principales.<br>

```{r}
table(factor(obesity_data_raw$CAEC, levels = c("no", "Sometimes", "Frequently", "Always")))
table(factor(obesity_data_raw$CAEC, levels = c("no", "Sometimes", "Frequently", "Always")))
barplot(table(factor(obesity_data_raw$CAEC, levels = c("no", "Sometimes", "Frequently", "Always"))), main="Diagrama de barras de la variable CAEC", col="light grey", border = "white")
```
la frecuencia con la que una persona come entre las comidas principales podría ser un buen indicador del sobrepeso. Sin embargo, la subjetivdad de las respuestas presentadas a los encuestados quita algo de esa potencia - la gran mayoría (más que 83%) tiene la percepción de comer entre comidas principales 'de vez en cuando' - pero no se especifica qué significa exactamente "de vez en cuando". Tampóco no da ningúna indicación de qué cantidad de comida se trata.<br>

#### **Transformaciones**
Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

* 0 - No<br>
* 1 - De vez en cuando<br>
* 2 - Frequentemente<br>
* 3 - Siempre <br>

Además, cambiamos el nombre de la variable - para que que tenga una capitalización en conformidad con las otras variables, y para evitar abreviacióne potencialmente confusas. La nombramos 'Between_Meals'.<br>


```{r}
obesity_data_preprocessed$Between_Meals = as.integer(
  ifelse(
    obesity_data_preprocessed$CAEC == "no", 0, ifelse(
      obesity_data_preprocessed$CAEC == "Sometimes", 1, ifelse(
        obesity_data_preprocessed$CAEC == "Frequently", 2, 3
      )
    )
  )
)
```


#### **1.13. SMOKE / Smoker**<br>
Se trata de una variable binaria que indica si el/la encuestado/-a es fumador, o no.<br>

```{r}
table(obesity_data_raw$SMOKE)

pie3D(table(as.factor(obesity_data_raw$SMOKE)), main = "Proporción de encuestados fumadores / no fumadores", col = c("white", "light grey"), border = "light grey", labels = c("no (n = 2067)", "yes (n = 385)"), theta = 1.5)
```
La relación entre fumar y peso corporal no es obvia; sin embargo, no sería de extrañar entre los dos. Podemos imaginar las siguentes relaciónes directas y no directas:<br>

* Podría ser que los ingredientes activos de los cigarrillos tuvieran un impacto directo en el metabolismo.<br>
* Podría ser que las personas más propensas a la adicción a los cigarrillos también tuvieran un mayor riesgo de obesidad.<br>
* Podría ser que un grupo de hombres llevara conscientemente una vida más sana y, por tanto, fumara menos y vigilara más su peso corporal.<br>

Sin duda, sería interesante seguir estudiando esta variable.<br>

#### **Transformaciones**<br>
Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

* 0 - No<br>
* 1 - Sí<br> 

Además, cambiamos el nombre de la variable - para que que tenga una capitalización en conformidad con las otras variables. La nombramos 'Smoker'.<br>

```{r}
obesity_data_preprocessed$Smoker = as.integer(
  ifelse(
  obesity_data_preprocessed$SMOKE == "no", 0, 1
  )
)
```

#### **1.14. CH20 / Water_Consumption**<br>
Se trata de una variable categórica ordinal, que indica cuanto agua consume el/la encuestado/-a por día, según la siguiente asignación.<br>

 * 1 - Menos que un litro<br>
 * 2 - Entre 1 litro y 2 litros<br>
 * 3 - Más que 2 litros<br>

```{r}
table(round(obesity_data_raw$CH2O))
barplot(table(round(obesity_data_raw$CH2O)), main="Diagrama de barras de la variable CH2O", col="light grey", border = "white")
```

Se espera que exista cierta relación negativa entre el consumo de agua y la obesidad - beber cantidades adecuadas de agua puede encajar en un estilo de vida consciente de la nutrición, lo que también podría reducir el riesgo de obesidad.<br>

#### **Transformaciones**<br>
En el conjunto de datos original, la variable CH2O tome valores descimales, algo aue no es conforme con el hecho que es una variable discreta. Por eso, vamos a redondearla. Después, para guardar la conformidad en el conjunto de datos, la transformamos de forma que el valor más bajo sea 0. La asinación nueva será, entonces:<br>

* 0 - Menos que un litro<br>
* 1 - Entre 1 litro y 2 litros<br>
* 2 - Más que 2 litros<br>

Además le nombramos 'Water_Consumption', para evitar abreviaciónes potencialmente confusas.<br>

```{r}
obesity_data_preprocessed$Water_Consumption = as.integer(
  round(
    ifelse(
      obesity_data_preprocessed$CH2O == 1, 0, ifelse(
        obesity_data_preprocessed$CH2O == 2, 1, 2
      )
    )
  )
)
```


#### 1.15. SCC / Calory_Monitoring<br>
Es una variable binaria que indica si el/la encuestado/-a sigue la ingesta de calorías, o no.<br>

```{r}
table(obesity_data_raw$SCC)

pie3D(table(as.factor(obesity_data_raw$SCC)), main = "Proporción de encuestados que sí / no monotorían si ingesto calórico", col = c("white", "light grey"), border = "light grey", labels = c("no (n = 2015)", "yes (n = 96)"), theta = 1.5)
```
Se espera que el peso de las personas que controlan su ingesta calórica sea inferior al de las que no lo hacen, por lo que existe una relación negativa razonablemente fuerte.<br>

#### **Transformaciones**

Aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

* 0 - No<br>
* 1 - Sí <br>

Además, cambiamos el nombre de la variable - para que que tenga una capitalización en conformidad con las otras variables. La nombramos 'Water_Consumption'.<br>

```{r}
obesity_data_preprocessed$Water_Consumption = as.integer(
  round(
    ifelse(
      obesity_data_preprocessed$CH2O == 1, 0, ifelse(
        obesity_data_preprocessed$CH2O == 2, 1, 2
      )
    )
  )
)
```


#### **1.16. FAF / Physical_Activity**<br>
Se trata de una variable discreta ordinal que indica cuanto tiempo dedica el/la encuestado/-a a la actividad física, de acuerdo con la siguiente asignación:<br>

* 0 - Nunca<br>
* 1 - 1 o 2 días<br>
* 2 - 2 a 4 días<br>
* 3 - 4 o 5 días<br>

(Obsérvese que el periodo de referencia sigue sin especificarse: suponemos que estamos hablando de días a la semana. En cualquier caso, cuanto mayor es la cifra, más tiempo se dedica al ejercicio físico.)<br>

```{r}
table(round(obesity_data_raw$FAF))
barplot(table(round(obesity_data_raw$FAF)), main="Diagrama de barras de la variable FAF", col="light grey", border = "white")
```

Es probable que haya una relación negativa entre el tiempo dedicado al ejercicio físico y el sobrepeso.<br>

#### **Transformaciones**
En el conjunto de datos original, la variable FAF tome valores descimales, algo aue no es conforme con el hecho que es una variable discreta. Por eso, vamos a redondearla.<br>

Además le nombramos 'Physical_Activity', para evitar abreviaciónes potencialmente confusas.<br>

```{r}
obesity_data_preprocessed$Physical_Activity = as.integer(
  round(
    ifelse(
      obesity_data_preprocessed$FAF == 1, 0, ifelse(
        obesity_data_preprocessed$FAF == 2, 1, 2
      )
    )
  )
)
```

#### **17. TUE / Tech_Devices_Use**
Se trata de una variable categorica ordinal que indica cuanto tiempo dedica el/la encuestado/-a al uso de medios técnicos, de acuerdo con la siguente asignación:<br>

* 0 - 0 a 2 horas<br>
* 1 - 3 a 5 horas<br>
* 2 - Más que 5 horas<br>

```{r}
table(round(obesity_data_raw$TUE))
barplot(table(round(obesity_data_raw$TUE)), main="Diagrama de barras de la variable TUE", col="light grey", border = "white")
```

Podría existir una relación positiva entre el uso de dispositivos electrónicos y la obesidad, suponiendo que las personas que pasan tiempo utilizando este tipo de dispositivos dediquen menos tiempo a actividades físicas. Así que este punto de vista supone, por así decirlo, que esta variable es la contrapartida de la variable FAF, que describe el nivel de actividad física (véase más arriba).<br>

#### **Transformaciones**<br>
En el conjunto de datos original, la variable TUE tome valores descimales, algo aue no es conforme con el hecho que es una variable discreta. Por eso, vamos a redondearla.<br>

Además le nombramos 'Physical_Activity', para evitar abreviaciónes potencialmente confusas.<br>

```{r}
obesity_data_preprocessed$Tech_Devices_Use = as.integer(round(obesity_data_preprocessed$TUE))
```


#### **1.18. CALC / Alcohol_Consumption**<br>
Se trata de una variable discreta ordinal que indica como de frequene el/la encuestado/-a consume alcohol.<br>

```{r}
table(factor(obesity_data_raw$CALC, levels = c("no", "Sometimes", "Frequently", "Always")))

barplot(table(factor(obesity_data_raw$CALC, levels = c("no", "Sometimes", "Frequently", "Always"))), main="Diagrama de barras de la variable CALC", col="light grey", border = "white")
```
Se sabe que el alcohol engorda, por lo que se espera una relación positiva entre la frecuencia del consumo de alcohol y la clase de peso.<br>

Sin embargo, como ha ocurrido con variables anteriores, hay que señalar que las categorías no están claramente delimitadas: ¿qué se entiende por 'a veces', por 'con frecuencia' y por 'siempre'?<br>

#### **Transformaciones**<br>
Para empezar, observamos que sólo una encuestada indicó que «siempre» bebe alcohol. Además, no está claro qué se entiende por esta categoría y en qué se diferencia del grupo de bebedores frecuentes de alcohol.<br>

Por estos motivos, eliminaremos la última categoría; la persona que se encuentre en esta categoría será reclasificada una categoría por debajo.<br>

Segudno, aplicamos 'label encoding', es decir, sustituiremos los valores que consisten de texto por valores numéricos, de acuerdo con la siguente asignación.<br>

 * 0 - Nunca<br>
 * 1 - De vez en cuando<br>
 * 2 - Frequentemente<br>
 
Por último, en este caso también cambiamos el nombre de la variable, para deshacernos de abreviaturas potencialmente confusas. La nombramos 'Alcohol_Consumption'.<br>

#### 1.19. MTRANS / Transport_Mean_Moto / Transport_Mean_Bike / Transport_Mean_Public_Transport / Transport_Mean_Foot<br>
MTRANS es una variabele categorica nominal. Indica el medio de transporte más usado por el/la encuestado/-a.<br>

```{r}
table(obesity_data_raw$MTRANS)

pie3D(table(as.factor(obesity_data_raw$MTRANS)), main = "Proporción de medio de transporte más usado", labels = c("Automobile (n = 457)", "Bike (n = 7)", "Motorbike (n = 11)", "Public_Transportation (n = 1580)", "Walking"), theta = 1.25, labelcex = 0.75)
```
Se espera cierta relación entre medio de transporte más usado y peso - Los que van a pie o en bicicleta queman más calorías que los que van en coche o en moto.<br>

El transporte público se situará en un punto intermedio, ya que implica desplazarse hasta la parada y, en algunos casos, hacer transbordo, dos cosas que también implican actividad física.<br>

#### **Transformaciones**<br>
Aplicamos one-hot encoding - es que decir, vamos a añadir una columna  por cada  valor que existe pare el variable "MTRANS"; si la fila contiene el valor para el variable MTRANS que coincide con las respectiva columna, el valor de esa columna  seŕá 1; en el caso contrario seŕa 0 .<br>

```{r}
obesity_data_preprocessed$Transport_Mean_Automobile = as.integer(
    ifelse(
      obesity_data_preprocessed$MTRANS == "Automobile", 1, 0
  )
)

obesity_data_preprocessed$Transport_Mean_Bike = as.integer(
  ifelse(
    obesity_data_preprocessed$MTRANS == "Bike", 1, 0
  )
)

obesity_data_preprocessed$Transport_Mean_Motorbike = as.integer(
  ifelse(
    obesity_data_preprocessed$MTRANS == "Motorbike", 1, 0
  )
)

obesity_data_preprocessed$Transport_Mean_Public_Transport = as.integer(
  ifelse(
    obesity_data_preprocessed$MTRANS == "Public_Transportation", 1, 0
  )
)

obesity_data_preprocessed$Transport_Mean_Foot = as.integer(
  ifelse(
    obesity_data_preprocessed$MTRANS == "Walking", 1, 0
  )
)
```

#### **Finalmente...**<br>
Por último, nos deshacemos de las columnas y del conjunto de datos que ya no necesitamos y colocamos las variables en un orden lógico.<br>

```{r}
#obesity_data_preprocessed = obesity_data_preprocessed[,c("Gender", "Age", "Height", "Weight", "BMI", "Weight_Class_Mendoza_De_La_Hoz", "Weight_Class_WHO", "Overweight_Family", "High_Caloric_Consumption", "Vegetable_Consumption", "Main_Meals", "Between_Meals", "Smoker", "Water_Consumption", "Calory_Monitoring", "Physical_Activity", "Tech_Devices_Use", "Alcohol_Consumption", "Transport_Mean_Automobile", "Transport_Mean_Motorbike", "Transport_Mean_Bike", "Transport_Mean_Public_Transport", "Transport_Mean_Foot")]

rm(obesity_data_raw)
```


## **2.Modelos Predictivos de Clasificación Binaria<br>**

## **2.1 Modelo Predictivo para detectar si un usuario es fumador o no<br>**

#### **2.1.1 Procede con la carga de datos<br>**
```{r}
datatrain <- read.csv('./data/ObesityDataSet_raw_and_data_sinthetic.csv')
```
#### **2.1.2 Revisión del Dataset para evaluar la variable a utilizar para el modelo predictivo<br>**
```{r}
str(datatrain)
summary(datatrain)
```
<br>
Con la revisión del dataset y sus variables se determina que para desarrollar el modelo predictivo si una persona es fumador o no, se debe seleccionar la variable Smoke, el cuál es una variable categórica binaria("Yes/NO"), y debe convertirse sus valores en binarios númerico para que puedan funcionar en un modelo de clasificación predictivo como Regresión Logistica(Binomial),Árboles de Decisión, KKN, SVm y aplicar  métricas como: accurary,F1-SCore, recall, precisión, matriz de confusión entre otras.
<br>
<br>
<br>


#### **2.1.3 Verificar la Factibilidad de la Variable SMOKE<br><br>**

Se debe analizar la variable "SMOKE", para determinar si es factible para predicir si una persona es o no fumador<br>

```{r}
#Se procede a convertir a binario
datatrain$SMOKE <- ifelse(datatrain$SMOKE == "yes", 1, 0)
```
```{r}
# Se verifica Frecuencia o cantidad de casos (NO Fumadores = 0/Fumadores =1)
table(datatrain$SMOKE)

# Se valida el %Porcentaje  de los datos observados (NO Fumadores = 0/Fumadores =1)
prop.table(table(datatrain$SMOKE))
```
<br>
Según la clasificación binaria o multiclase si los datos de la variable estudiada
presenta observaciones mayor al 40%, esto indica que el modelo puede entrenarse, pero si las observaciones es menor al 10% nos indica que los datos están desbalanceados, por lo que en un modelo de entrenamiento no va hacer factible o creible, ya que va favorecer los resultados de la observación mayoritaria en este caso "No Fumadores" que representa el 97%  e ignora la observación minoritaria en este caso "Si Fumadores" que representa 3% del dataset.<br>

Para que funcione bien el modelo de predicción debe aplicarse técnicas adicionales para balancear los datos, pero para efectos de este proyecto vamos realizar la predicciones sin hacer el balanceo validar la teoría que indica esto afectaria los modelos predictivos y sus métricas<br>


#### **2.1.4 Definimos los datos entrenamiento sugeridos (70% Entrenamiento & 30% Prueba) para probar un modelo predicto, para este caso hemos seleccionado la regresión logística(Binomial)<br><br>**
```{r}
ind <- sample(1:dim(datatrain)[1], 0.7 * dim(datatrain)[1]) #Selecciona datos 
datatrain.set <- datatrain[ind, ] #70%Datos para entrenamiento
datatest.set <- datatrain[-ind, ] #30%Datos para pruebas
#Datos a Entrenar
dim(datatrain.set)
#Datos a Probar
dim(datatest.set)
#Se procede a probar el modelo de regresión logistíca binaria con los datos para entrenamiento
model <- glm(SMOKE ~.,family=binomial(link='logit'),data=datatrain.set) 
summary(model)
#Se ejecuta la predicción con los datos modelados y set de pruebas
pred.train <- predict(model,datatest.set)
pred.train <- ifelse(pred.train > 0.5,1,0)
```
<br>
<br>
Regresión logística nos indica que parámetro binomial está cerca de 1, por lo que nos sugiere que los datos estudiados no tiene exceso de variabilidad(sobre dispersión) , el null deviance y residual deviance presenta valores menores a 300, lo que sugiere que modelo mejora al incluir predictores,y nos presenta 15 a 20 iteraciones por lo que nos da equilibrio razonable entre ajuste y complejidad del modelo al hacer predicciones,lo que nos indica que SMOKE se le puede aplicar un modelo predictivo cuyas variables mas importantes son AGE para predecir.
<br>
<br>

#### **2.1.5 Aplicacion de Métricas<br><br>**


##### **Accuracy:(Número de predicciones correctas/Número Datos Pruebas)<br>**

```{r}
mean(pred.train==datatest.set$SMOKE)

```
El accuracy nos indica que el modelo predictivo tiene una precision del 97% para los datos de pruebas, lo cual nos ayuda determinar que el 97% de las predicciones coinciden con los valores reales de variable "SMOKE" en el conjunto de data de prueba, lo cual nos comprueba el punto 2.1.3 sobre desbalanceo de los datos. <br><br>

##### **Presicion y Recall <br>**

El cálculo de precisión nos ayuda encontra los verdaderos positivos entre todos los casos predichos, y el recall permitirá mide los verdaderos positivos entre los casos positivos.<br>
```{r}
calPre_call<-table(pred.train,datatest.set$SMOKE)
presicion<- calPre_call[1,1]/(sum(calPre_call[1,]))
recall<- calPre_call[1,1]/(sum(calPre_call[,1]))
#Imprime Precision
presicion
#Imprime Recall
recall
```
Precisión tiene un  resultado 0.97 aproximadamente, lo que nos indica que el 97% de las predicciones positivas para la variable smoke = 0 ,  lo cual el modelo comete pocos falsos positivos.
<br>
Recall dio como resultado 0.99, lo que nos demuestra que el 99% de las prediciones encontró una observación positiva smoke = 0, lo que indica que el modelo no da falsos negativos, lo que nos comprueba que hay desbalanceo de los datos "No fumadores" / "Si Fumadores"<br>
<br>

##### **FI-SCORE <br>**
F1-CORE es una metrica combinada de precisión y recall<br>
```{r}
F1<- 2*presicion*recall/(presicion+recall)
F1
```
<br>
F1 tiene una como valor 0.98 por lo que nos indica que el hay un buen balance entre precisión y recall, lo que predice la mayoria valores positivos  lo que indica que no comete muchos errores en la clasificación, por lo que el modelo predición esta ajustado y confiable para predecir la variable Smoke segun la teoria, pero en realidad esto no es correcto, porque solo toma en cuenta el porcentaje datos "NO FUMADORES" que representa 97% de la datos de la variable.<br>
<br>

##### **Matriz de Confusión <br>**

Se averigua el resultado de la matriz de confusión para averiguar el rendimiento del modelo de clasificación<br>
```{r}
table(Predicted = pred.train, Actual = datatest.set$SMOKE)
```
- Verdaderos Negativos(tn) En la matriz de confusión obtenemos los siguientes valores<br> 
El modelo predijo smoke = 0 cuando realmente era 0. <br>
-Falsos Positivos(FP)=15 , predijo incorrectamente smoke = 1 cuando realmente era 0.<br>
-Falsos Negativos(FN)=4, predijo incorrectamente smoke = 0 cuando la clase real era 1. <br>
-Verdaderos Positivos = 0, no predijo correctamente ningun caso de smoke = 1.<br><br>

Esto nos comprueba la teoria del punto 2.3.1, los datos utilizados no son factibles para hacer prediciones, porque ha ignorado por completo casos de "SI FUMADORES", el cual si existieran más del 40% habria verdaderos positivos, este caso el modelo a ignorado completamente las personas de nuestro dataset que si son fumadores, para cuestiones de estadísticas o estudios  no podríamos dar una conclusión segura de cuales variables o que motiva a una persona hacer fumador o no. 

#### **2.1.6 Conclusión del Caso Detectar si una persona es fumador o no <br>**
<br>
Se valida las métricas el accuracy, precisión, recall, están por encima 97% lo cuál nos indica que el modelo tiene un buen desempeño para predicir correctamente los datos de (No fumadores smoke = 0/Si Fumadores smoke =1 ), según lo estudiado esto no es lo normal para un modelo.

Según lo revisado desde el inicio de estudio del modelo predictivo los datos de la variable smoke indica hay un desbalanceo de los datos, por lo que siempre va tomar los resultados de los "No Fumadores", e ignorar los datos "Si Fumadores", lo que afecta el rendimiento del modelo para predecir correctamente, y en la matriz de confusión se observa correctamente la anomalia, se dan falsos negativos y falsos positivos, pero ningun caso positivo de si fumadores , por lo que modelo predictivo no es aplicable para predecir la variable "smoke"<br><br>

## **2.2 Modelo Predictivo para detectar si una persona controla o no las calorías<br><br>**

Realizar un modelo predictivo de clasificaciónbinaria para detectar si un usuario controla o no las calorías ingeridas.El análisis se apoyará sobre las mismas variables utilizadas previamente.<br>

#### **2.2.1 Carga y lectura de los datos <br>**
```{r}
dataset <- read.csv("./data/obesity_data_set_preprocessed.csv", header = T, sep = ";")

str(dataset)
head(dataset)
```
#### **2.2.2 Cambio de formato para convertir la coma en punto y transformar la columnaS a numérico**<br>
```{r}
dataset$Height <- as.numeric(gsub(",", ".", dataset$Height))
dataset$BMI <- as.numeric(gsub(",", ".", dataset$BMI))

str(dataset)
summary(dataset)
```

#### **2.2.3 Convertimos la variable objetivo --Calory_Monitoring--**<br>

Se debe convertir la variable --Calory_Monitoring-- a factor para asegurarnos que R entiende que se trata de un problema de clasificación.<br>
```{r}
dataset$Calory_Monitoring <- as.factor(dataset$Calory_Monitoring)
```

#### **2.2.4  Seleccionamos los datos de entrenamiento y Prueba para la variable objetio --Calory_Monitoring--**<br>
Dividimos los datos para su entrenamiento (80%) y prueba (20%). La variable objetivo será Calory_Monitoring.<br>
```{r}
set.seed(42)  # Semilla para reproducibilidad

train_index <- createDataPartition(dataset$Calory_Monitoring, p = 0.8, list = FALSE)

train_data <- dataset[train_index, ]  # 80% Datos para entrenamiento
test_data <- dataset[-train_index, ]  # 20% Datos para prueba

dim(train_data)
dim(test_data)
```
#### **2.2.5 Selecciona el modelo de regresión logística binomial para el estudio del variable Calory_Monitoring **<br>

Utilizamos un modelo de regresión logística para predecir si la persona controla las calorías. <br>
Utilizamos todas las variables del dataset como predictoras para cruzarlas con nuestra variable objetivo<br>
```{r}
model <- glm(
  Calory_Monitoring ~ .,       # Variable objetivo y todas las predictoras
  family = binomial(link = 'logit'), 
  data = train_data
)
summary (model)
str(dataset)
print(model)
```
#### **2.2.6 Evaluación del Modelo de Regresión Logística **<br>

#### **--------Resultado del sumario**<br>
```{r}
 glm(formula = Calory_Monitoring ~ ., family = binomial(link = "logit"), 
      data = train_data)
```
De estos resultados se deduce a priori que las variables #High_Caloric_Consumption,
Vegetable_Consumption, Weight_Class_WHO y Age tienen un impacto significatvo a la hora
de predecir si se controla la ingesta de calorías. Todos ellos tiene p-valores muy bajos,
 (<0.01)<br>

#### **2.2.6 Ejecutamos las prediciones para la comprobar patrones**<br>
 
Hacemos las predicciones en el conjunto de prueba para comprobar si nuestro modelo está generalizando bien los patrones aprendidos.<br>

```{r}
predictions <- predict(model, newdata = dataset[-train_index, ], type = "response")
```
#### **2.2.7 Convertimos probabilidades en clases binarias (umbral = 0.5)**<br>
```{r}
predicted_classes <- ifelse(predictions > 0.5, 1, 0)

head(predictions)
head(predicted_classes)
```
#### **2.2.8 Análisis del rendimiento de nuestro modelo mediante el cálculo de métricas**<br>
Ejecuta el estudio de la matriz de confusión, precisión, recall y FI-Score para ver como se comporta
todo el conjunto (o datos) de prueba<br>

#### **Matriz de confusión**<br>
```{r}
confusion_matrix <- table(Predicted = predicted_classes, Actual = dataset$Calory_Monitoring[-train_index])
print(confusion_matrix)
```
##### Interpretación del resultado:<br>
El modelo es capaz de predecir con un elevado grado de precisión (403 de un total de 422 observaciones en el conjunto de prueba) los 'true negatives', en este caso, aquellos que no controlan las calorías (0), pero arroja 19 falsos negativos y no es capaz de predecir nunca la clase 1, aquellos que controlan las calorías. Podría deberse a un umbral de clasificación demasiado alto o a un sesgo del modelo hacia la clase 0.<br> 

#### **Cálculo de la precisión o accuracy**<br>
```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Precisión del modelo:", round(accuracy, 4), "\n")
```
##### Interpretación del resultado:<br>
la precisión arroja un valor de 0.955, lo que significa que significa que el modelo clasifica correctamente el 95% de las observaciones en el conjunto de prueba, lo cual es un buen desempeño a falta de evaluar otras métricas<br>


#### **Matriz de confusión con el umbral rebajado a 0.4**<br>
```{r}
predicted_classes <- ifelse(predictions > 0.4, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = dataset$Calory_Monitoring[-train_index])
print(confusion_matrix)
```
#### **¿Existe un desbalance de clases con la subrepresentación de la clase 1?**<br>
```{r}
table(dataset$Calory_Monitoring)
```
#### **Recall**<br>
```{r}
TP <- confusion_matrix["1", "1"]  # True Positives
FN <- confusion_matrix["0", "1"]  # False Negatives
recall <- TP / (TP + FN)
cat("Recall:", round(recall, 4), "\n")
```
El recall arroja un valor de 0, lo que significa que el modelo no es capaz de capturar 
correctamente la clase 1, aquellos que controlan las calorías.

#### **2.2.9 Validación y Prueba con modelo RandomForest**<br>
Dado que nuestro modelo de regresión logística sigue dando problemas, probaremos con un modelo más robusto frente al balance de clases. este caso<br>
```{r}
library(randomForest)
rf_model <- randomForest(Calory_Monitoring ~ ., data = train_data, ntree = 100)
rf_predictions <- predict(rf_model, test_data)
rf_confusion <- table(Predicted = rf_predictions, Actual = dataset$Calory_Monitoring[-train_index])

```
#### **Matriz de confusión con RandomForest**<br>
```{r}
print(rf_confusion)
```


#### **Cálculo del Accuracy con el nuevo modelo RForest**<br>
```{r}
accuracy <- (TP + FN) / sum(confusion_matrix)
cat("Precisión (Accuracy):", round(accuracy, 4), "\n")
```

#### **Cálculo del Recall**<br>
```{r}
recall <- TP / (TP + FN)
cat("Recall:", round(recall, 4), "\n")
```
#### **Cálculo de la precisión**<br> 
```{r}
precision <- TP / (TP + FN)
cat("Precision:", round(precision, 4), "\n")
```
#### **Cálculo del F1-Score**<br> 
```{r}
f1_score <- 2 * (precision * recall) / (precision + recall)
cat("F1-Score:", round(f1_score, 4), "\n")
```
##### **Conclusión del Modelo Predictivo si una persona controla o no las calorías**<br> 
De los resultados obtenidos al calcular las métricas clave para analizar este modelo predictivo se deduce que es modelo es mejorable. Sus fortalezas estriban en que es capaz de clasificar con una alta precisión el total de las observaciones (Accuracy: 97.16%) y nunca se equivoca a la hora de predecir quién controla las calorías (Precision:100%). Por el contrario, tiene también serias deficiencias. Su bajo Recall (36.8%) indica que solo identifica correctamente cuatro de cada diez casos reales de la clase 1, o lo que es lo mismo, de aquellas personas que sí controlan las calorías. De todo ello ser deriva también un sesgo hacia la clase mayoritaria o clase 0, esa mayoría que no controla la ingesta de calorías.<br> 

## **3.Modelos Predictivos de Clasificación Multiclase<br>**

#### **3.1 Cargar los datos desde el archivo <br>**
getwd()
file_path <- "./data/obesity_data_set_preprocessed.csv"
file.exists("./data/obesity_data_set_preprocessed.csv")
data <- read.csv(file_path, sep = ";", header = TRUE, stringsAsFactors = FALSE)

#### **3.2 Explorar los datos<br>**
head(data)

#### **Resultado --------------------------------------------------------------<br>**
Gender        Age     Height      Weight        BMI Weight_Class_Mendoza_De_La_Hoz Weight_Class_WHO Overweight_Family
1      0 -0.5216176 -0.8741725 -0.86240301 -0.6632291                              1                1                 1
2      0 -0.5216176 -1.9451986 -1.16786153 -0.6817273                              1                1                 1
3      1 -0.2070077  1.0536746 -0.36603292 -0.7407015                              1                1                 1
4      1  0.4222122  1.0536746  0.01579022 -0.3557160                              2                2                 0
5      1 -0.3643127  0.8394694  0.13033717 -0.1619207                              3                2                 0
6      1  0.7368222 -0.8741725 -1.28240847 -1.1860489                              1                1                 0
High_Caloric_Consumption Vegetable_Consumption Main_Meals Between_Meals Smoker Water_Consumption Calory_Monitoring
1                        0                     1          2             1      0                 1                 0
2                        0                     2          2             1      1                 2                 1
3                        0                     1          2             1      0                 1                 0
4                        0                     2          2             1      0                 1                 0
5                        0                     1          0             1      0                 1                 0
6                        1                     1          2             1      0                 1                 0
Physical_Activity Tech_Devices_Use Alcohol_Consumption Transport_Mean_Automobile Transport_Mean_Motorbike
1                 0                1                   0                         0                        0
2                 3                0                   1                         0                        0
3                 2                1                   2                         0                        0
4                 2                0                   2                         0                        0
5                 0                0                   1                         0                        0
6                 0                0                   1                         1                        0
Transport_Mean_Bike Transport_Mean_Public_Transport Transport_Mean_Foot
1                   0                               1                   0
2                   0                               1                   0
3                   0                               1                   0
4                   0                               0                   1
5                   0                               1                   0
6                   0                               0                   0
> 

str(data)  

#### **Resultado --------------------------------------------------------------<br>**
'data.frame':	2111 obs. of  23 variables:
  $ Gender                         : Factor w/ 2 levels "0","1": 1 1 2 2 2 2 1 2 2 2 ...
$ Age                            : num  -0.522 -0.522 -0.207 0.422 -0.364 ...
$ Height                         : num  -0.874 -1.945 1.054 1.054 0.839 ...
$ Weight                         : num  -0.8624 -1.1679 -0.366 0.0158 0.1303 ...
$ BMI                            : num  -0.663 -0.682 -0.741 -0.356 -0.162 ...
$ Weight_Class_Mendoza_De_La_Hoz : int  1 1 1 2 3 1 1 1 1 1 ...
$ Weight_Class_WHO               : Factor w/ 6 levels "0","1","2","3",..: 2 2 2 3 3 2 2 2 2 2 ...
$ Overweight_Family              : Factor w/ 2 levels "0","1": 2 2 2 1 1 1 2 1 2 2 ...
$ High_Caloric_Consumption       : Factor w/ 2 levels "0","1": 1 1 1 1 1 2 2 1 2 2 ...
$ Vegetable_Consumption          : Factor w/ 3 levels "0","1","2": 2 3 2 3 2 2 3 2 3 2 ...
$ Main_Meals                     : Factor w/ 4 levels "0","1","2","3": 3 3 3 3 1 3 3 3 3 3 ...
$ Between_Meals                  : Factor w/ 4 levels "0","1","2","3": 2 2 2 2 2 2 2 2 2 2 ...
$ Smoker                         : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
$ Water_Consumption              : Factor w/ 3 levels "0","1","2": 2 3 2 2 2 2 2 2 2 2 ...
$ Calory_Monitoring              : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
$ Physical_Activity              : Factor w/ 4 levels "0","1","2","3": 1 4 3 3 1 1 2 4 2 2 ...
$ Tech_Devices_Use               : Factor w/ 3 levels "0","1","2": 2 1 2 1 1 1 1 1 2 2 ...
$ Alcohol_Consumption            : Factor w/ 3 levels "0","1","2": 1 2 3 3 2 2 2 2 3 1 ...
$ Transport_Mean_Automobile      : Factor w/ 2 levels "0","1": 1 1 1 1 1 2 1 1 1 1 ...
$ Transport_Mean_Motorbike       : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 2 1 1 1 ...
$ Transport_Mean_Bike            : Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
$ Transport_Mean_Public_Transport: Factor w/ 2 levels "0","1": 2 2 2 1 2 1 1 2 2 2 ...
$ Transport_Mean_Foot            : Factor w/ 2 levels "0","1": 1 1 1 2 1 1 1 1 1 1 ...
> 

  
#### **3.3 Limpiar las columnas para reemplazar comas por puntos y convertir a numérico<br>**
data$Height <- as.numeric(gsub(",", ".", data$Height))
data$Weight <- as.numeric(gsub(",", ".", data$Weight))
data$BMI <- as.numeric(gsub(",", ".", data$BMI))

#### **3.4 Verificacion si la limpieza quedó como esperamos<br>**
summary(data[, c("Height", "Weight", "BMI")])

#### **Resultado ---------------------------------------------------------------<br>**

Height             Weight             BMI         
Min.   :-2.69492   Min.   :-1.8170   Min.   :-2.0662  
1st Qu.:-0.76707   1st Qu.:-0.8051   1st Qu.:-0.6702  
Median :-0.01735   Median :-0.1369   Median :-0.1212  
Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000  
3rd Qu.: 0.73237   3rd Qu.: 0.7794   3rd Qu.: 0.7833  
Max.   : 2.98152   Max.   : 3.2995   Max.   : 2.6298  



#### **3.5 Recalculo del BMI<br>**
data$BMI <- data$Weight / (data$Height^2)
summary(data$BMI)

#### **Resultado ----------------------------------------------------------------<br>**
Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-4639.879    -1.264    -0.155   -70.630     1.195  5886.147 


#### **3.6 Convertir variables categóricas <br>**
categoricas <- c("Gender", "Overweight_Family", "High_Caloric_Consumption", 
                 "Vegetable_Consumption", "Main_Meals", "Between_Meals", 
                 "Smoker", "Water_Consumption", "Calory_Monitoring", 
                 "Physical_Activity", "Tech_Devices_Use", "Alcohol_Consumption", 
                 "Transport_Mean_Automobile", "Transport_Mean_Motorbike", 
                 "Transport_Mean_Bike", "Transport_Mean_Public_Transport", 
                 "Transport_Mean_Foot", "Weight_Class_WHO")
data[categoricas] <- lapply(data[categoricas], as.factor)

#### **3.7 Escalar variables continuas <br>**

continuas <- c("Age", "Height", "Weight", "BMI")
preproc <- preProcess(data[, continuas], method = c("center", "scale"))
data[, continuas] <- predict(preproc, data[, continuas])
summary(data)

#### ** Resultado ---------------------------------------------------------------**<br>
Gender        Age              Height             Weight             BMI          Weight_Class_Mendoza_De_La_Hoz
0:1043   Min.   :-1.6228   Min.   :-2.69492   Min.   :-1.8170   Min.   :-7.2700   Min.   :0.000                 
1:1068   1st Qu.:-0.6789   1st Qu.:-0.76707   1st Qu.:-0.8051   1st Qu.: 0.1104   1st Qu.:1.000                 
Median :-0.2070   Median :-0.01735   Median :-0.1369   Median : 0.1121   Median :3.000                 
Mean   : 0.0000   Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000   Mean   :3.112                 
3rd Qu.: 0.2649   3rd Qu.: 0.73237   3rd Qu.: 0.7794   3rd Qu.: 0.1143   3rd Qu.:5.000                 
Max.   : 5.7706   Max.   : 2.98152   Max.   : 3.2995   Max.   : 9.4776   Max.   :6.000                 
Weight_Class_WHO Overweight_Family High_Caloric_Consumption Vegetable_Consumption Main_Meals Between_Meals Smoker  
0:267            0: 385            0: 245                   0:  33                0: 316     0:  51        0:2067  
1:306            1:1726            1:1866                   1: 600                1: 176     1:1765        1:  44  
2:565                                                       2:1478                2:1470     2: 242                
3:368                                                                             3: 149     3:  53                
4:338                                                                                                              
5:267                                                                                                              
Water_Consumption Calory_Monitoring Physical_Activity Tech_Devices_Use Alcohol_Consumption Transport_Mean_Automobile
0: 485            0:2015            0:720             0:952            0: 639              0:1654                   
1:1110            1:  96            1:776             1:915            1:1401              1: 457                   
2: 516                              2:496             2:244            2:  71                                       
3:119                                                                           


Transport_Mean_Motorbike Transport_Mean_Bike Transport_Mean_Public_Transport Transport_Mean_Foot
0:2100                   0:2104              0: 531                          0:2055             
1:  11                   1:   7              1:1580                          1:  56 


#### **3.8 Preparar datos de entrenamiento y prueba <br>**

set.seed(200)
trainIndex <- createDataPartition(data$Weight_Class_WHO, p = 0.8, list = FALSE)
data$Weight_Class_WHO <- as.factor(data$Weight_Class_WHO)
trainIndex <- createDataPartition(data$Weight_Class_WHO, p = 0.8, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

#### **3.9 Entrenar un modelo Random Forest <br>**
set.seed(200)
modelo_rf <- randomForest(Weight_Class_WHO ~ ., data = trainData, ntree = 100)
print(modelo_rf)


#### **Resultado ---------------------------------------------------------------**
Call:
  randomForest(formula = Weight_Class_WHO ~ ., data = trainData,      ntree = 100) 
Type of random forest: classification
Number of trees: 100
No. of variables tried at each split: 4

OOB estimate of  error rate: 2.66%
Confusion matrix:
  0   1   2   3   4   5 class.error
0 211   3   0   0   0   0 0.014018692
1   6 231   8   0   0   0 0.057142857
2   0   1 449   2   0   0 0.006637168
3   0   0   3 286   6   0 0.030508475
4   0   0   1   5 257   8 0.051660517
5   0   0   0   0   2 212 0.009345794


#### **3.10 Predicciones en el conjunto de prueba <br>**
pred_rf <- predict(modelo_rf, testData)
print(pred_rf)


#### **Resultado ---------------------------------------------------------------**
20   32   34   39   42   45   51   60   64   79   80   88   92  109  119  134  135  141  147  152  156  166  177  185  186 
2    2    2    1    1    1    1    0    1    3    1    2    1    3    1    1    3    1    1    1    1    4    1    2    2 
193  194  195  201  202  204  207  214  218  223  227  234  237  238  244  253  259  260  269  272  273  289  292  293  295 
2    1    3    3    3    3    3    1    2    1    1    2    1    1    2    2    2    3    1    1    1    1    0    1    3 
301  304  306  307  308  309  311  312  314  332  333  339  341  351  354  368  369  373  377  378  379  388  389  408  411 
1    1    4    1    1    1    0    1    1    1    1    2    1    1    1    2    2    1    1    1    1    3    3    2    1 
412  415  425  431  432  436  437  439  446  450  452  453  455  463  464  467  468  471  476  485  489  495  496  505  515 
2    3    2    3    1    2    1    1    1    1    1    1    1    2    1    1    1    1    2    2    1    1    1    5    0 
517  523  525  538  539  543  545  546  548  551  552  556  558  559  571  572  573  576  577  582  590  596  597  598  603 
0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0 
604  614  619  626  646  649  651  658  668  671  672  673  678  687  691  693  699  700  703  704  706  736  740  745  767 
0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2 
769  771  774  776  781  785  787  794  797  805  808  815  817  820  828  832  837  841  851  861  885  886  888  890  896 
2    2    2    2    2    1    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
897  901  904  906  909  910  911  912  914  920  925  929  954  964  979  982  990  992 1006 1008 1009 1011 1020 1021 1022 
2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
1027 1028 1029 1033 1044 1046 1048 1050 1053 1054 1055 1059 1060 1077 1078 1083 1094 1096 1099 1102 1109 1110 1112 1113 1114 
2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2 
1117 1120 1124 1127 1129 1144 1148 1149 1154 1163 1170 1172 1175 1181 1183 1195 1198 1201 1207 1209 1212 1216 1219 1222 1228 
2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    2    3    3    3    3    3 
1234 1243 1248 1250 1252 1254 1266 1271 1282 1303 1310 1315 1335 1338 1339 1340 1345 1351 1353 1355 1358 1361 1362 1364 1375 
3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3 
1382 1383 1384 1395 1401 1405 1410 1413 1422 1428 1429 1431 1438 1448 1449 1463 1465 1467 1470 1471 1472 1479 1484 1488 1505 
3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3 
1518 1520 1524 1532 1534 1539 1543 1545 1550 1551 1552 1555 1559 1561 1566 1572 1573 1582 1586 1591 1599 1600 1602 1607 1614 
4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4 
1617 1625 1638 1645 1659 1662 1663 1668 1672 1676 1684 1687 1694 1696 1698 1699 1705 1719 1721 1734 1737 1738 1746 1747 1751 
4    4    4    4    4    3    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    3    4    4    4 
1755 1769 1776 1781 1787 1791 1792 1793 1795 1807 1831 1835 1844 1852 1854 1856 1857 1859 1868 1871 1876 1877 1880 1881 1885 
4    4    4    4    4    4    4    4    4    5    4    5    4    5    5    5    5    5    5    5    5    5    5    5    5 
1893 1899 1900 1903 1911 1918 1931 1932 1938 1942 1943 1945 1946 1950 1963 1968 1973 1975 1979 1993 2000 2002 2005 2008 2009 
5    5    5    4    5    5    4    4    5    5    5    5    5    5    5    4    5    5    5    5    5    5    5    4    5 
2010 2022 2024 2031 2033 2036 2046 2049 2052 2053 2054 2060 2061 2067 2068 2074 2078 2085 2086 2089 
5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5 
Levels: 0 1 2 3 4 5



#### **3.11 Evaluación del modelo<br>**
conf_rf <- confusionMatrix(pred_rf, testData$Weight_Class_WHO)
print(conf_rf)

#### **Resultado --------------------------------------------------------------- <br>**
**Confusion Matrix and Statistics**

Reference
Prediction   0   1   2   3   4   5
0  51   2   0   0   0   0
1   2  56   0   0   0   0
2   0   3 113   1   0   0
3   0   0   0  70   1   0
4   0   0   0   2  64   0
5   0   0   0   0   2  53

Overall Statistics

Accuracy : 0.969           
95% CI : (0.9477, 0.9834)
No Information Rate : 0.269           
P-Value [Acc > NIR] : < 2.2e-16       

Kappa : 0.9622          

Mcnemar's Test P-Value : NA              

#### Statistics by Class:

                     Class: 0 Class: 1 Class: 2 Class: 3 Class: 4 Class: 5
Sensitivity            0.9623   0.9180   1.0000   0.9589   0.9552   1.0000
Specificity            0.9946   0.9944   0.9870   0.9971   0.9943   0.9946
Pos Pred Value         0.9623   0.9655   0.9658   0.9859   0.9697   0.9636
Neg Pred Value         0.9946   0.9862   1.0000   0.9914   0.9915   1.0000
Prevalence             0.1262   0.1452   0.2690   0.1738   0.1595   0.1262
Detection Rate         0.1214   0.1333   0.2690   0.1667   0.1524   0.1262
Detection Prevalence   0.1262   0.1381   0.2786   0.1690   0.1571   0.1310
Balanced Accuracy      0.9784   0.9562   0.9935   0.9780   0.9748   0.9973


**Matriz de confusión<br>**

conf_matrix_table <- as.data.frame(conf_rf$table)
ggplot(data = conf_matrix_table, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 4) +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "Matriz de Confusión - Random Forest", x = "Clases Reales", y = "Clases Predichas") +
  theme_minimal()<br>

**Precisión global<br>**
accuracy <- conf_rf$overall["Accuracy"]
cat("Precisión del modelo:", accuracy, "\n")<br>

**Resultado<br>**

Precisión del modelo: 0.9690476 <br>

** Métricas por clase<br>**
metrics <- as.data.frame(conf_rf$byClass)<br>
metrics$Clase <- rownames(metrics)<br>

**Graficar precisión, recall y F1 por clase<br>**
ggplot(metrics, aes(x = Clase)) +
  geom_bar(aes(y = Precision), stat = "identity", fill = "steelblue", alpha = 0.7) +
  geom_bar(aes(y = Recall), stat = "identity", fill = "darkgreen", alpha = 0.7, position = "dodge") +
  geom_bar(aes(y = F1), stat = "identity", fill = "purple", alpha = 0.7, position = "dodge") +
  labs(title = "Métricas por Clase - Random Forest", y = "Valor", x = "Clase") +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 1))<br>

**Matriz de confusión y métricas<br>**
conf_rf <- confusionMatrix(pred_rf, testData$Weight_Class_WHO)<br>
print(conf_rf)<br>

**Resultado <br>**
Confusion Matrix and Statistics

          Reference
Prediction   0   1   2   3   4   5
         0  51   2   0   0   0   0
         1   2  56   0   0   0   0
         2   0   3 113   1   0   0
         3   0   0   0  70   1   0
         4   0   0   0   2  64   0
         5   0   0   0   0   2  53

Overall Statistics
                                          
               Accuracy : 0.969           
                 95% CI : (0.9477, 0.9834)
    No Information Rate : 0.269           
    P-Value [Acc > NIR] : < 2.2e-16  <br>     
                                          
                          
### **Conclusiones Predicion Multiclase:<br>**
El enunciado nos solicitaba realizar un modelo predictivo multiclase para obtener
el grado de obesidad de una persona. La variable objetivo que utilizamos fue 
Weight_Class_WHOcomo y empleamos un modelo como Random Forest para la predicción<br>

El modelo demostró predecir en un alto porcentaje el grado de obesidad de una persona de un 96.9%, o sea casi un 97% de las predicciones fueron correctas.<br>

El CI 95%, muestra que la exactitud estimada se encuentra entre 94.77% y 98.34%, lo que confirma la estabilidad del modelo.<br>

La variable que más influencia obtuvo en el análisis fue el BMI (Índice de Masa Corporal)
para predecir el grado de obesidad, lo cual es consistente con el hecho de que esta métrica está directamente relacionada con las categorías de la OMS.<br>

Otras variables importantes que influyeron en el resultado fueron:
1. Consumo calórico elevado: Indicativo de una dieta que puede influir directamente en el peso.<br>
2. Actividad física: Un factor crítico para controlar el peso y mantener un IMC saludable.<br>
3. Consumo de verduras y número de comidas principales: Hábitos alimenticios que influyen en la regulación del peso.<br>

La matriz de confusión muestra una excelente capacidad para diferenciar entre clases, con solo unas pocas confusiones entre clases adyacentes, como Obesidad II y Obesidad I.<br>

Las métricas por clase muestran<br>


Clase	             Precisión	Sensibilidad	F1-Score
Clase 0 (Infrapeso)	97%	      94%	            95%
Clase 1 (Normal)  	96%	      97%	            96%
Clase 2 (Sobrepeso)	99%	      97%	            98%
Clase 3 (Obesidad I)	97%	    96%	            96%
Clase 4 (Obesidad II)	95%	    93%	            94%
Clase 5 (Obesidad III)	98%	  98%	           98%

En resumen podemos indicar que el modelo es confiable para clasificar el grado de obesidad, aunque tiene ligeras confusiones entre clases cercanas.<br>

## **4. Técnica de Clustering para Segmentar a la Población del Data Set**

#### **4.1 Convertimos FAVC ("yes"/"no") a valores numéricos (1/0)<br><br>**
```{r}
data<- read.csv('./data/ObesityDataSet_raw_and_data_sinthetic.csv')
data$FAVC <- ifelse(data$FAVC == "yes", 1, 0)
```
#### **4.2 Crear una columna nueva que será el BMI (Body Mass Index).<br><br>** 
Es importante porque relaciona peso y altura y es comunmente usada para analizar patrones con la salud. A parte de eso, simpifica el clustering al combinar altura y peso en una variable<br>
```{r}
data$BMI <- data$Weight / (data$Height^2)
```
#### **4.3 Seleccionamos las variables para el clustering: FAVC (consumo de comida calórica), FCVC (consumo de vegetales) y BMI. Creamos un dataset con estas columnas para simplificar el análisis<br><br>**
```{r}
data_clustering <- data[, c("FAVC", "FCVC", "BMI")]
```

#### **4.4 Verificamos el set dentro del set creado:<br><br>**
```{r}
head(data_clustering)
```
#### **4.5 Determinaremos el número de clusters con el Método del codo<br><br>**

```{r}
set.seed(101)
```
#### **4.6 Ejecutamos k-means con un número arbitrario de clusters (3)<br><br>**
```{r}
clustering_result<-kmeans(data_clustering, center=3, nstart=20)
```
#### **4.7 Visualizamos los resultados <br><br>**
```{r}
clustering_result
```

#### **4.8 Evaluamos el clustering creando una tabla para analizar cómo se relacionan los clusters con una variable conocida <br><br>**
```{r}
table(clustering_result$cluster,data$NObeyesdad)
```
#### **4.9 Evaluamos si 3 es un buen número de clusters o si necesitamos ajustar<br><br>**
```{r}
tot.withinss <- vector(mode = "numeric", length = 10)
for (i in 1:10) {
  kmeans_test <- kmeans(data_clustering, centers = i, nstart = 20)
  tot.withinss[i] <- kmeans_test$tot.withinss}
```
#### **4.10 Graficamos el Método del Codo <br><br>**
```{r}
plot(1:10, tot.withinss, type = "b", pch = 19, 
     main = "ELBOW GRAPH")
```
Observamos que 3 es un buen número pues después del 3 la curva se vuelve más plana por lo que aumentar el número de clusters no aportará una mejora significativa.<br><br>

#### **4.11 Visualizamos los clusters <br><br>**
```{r}
library(cluster)
clusplot(data_clustering, clustering_result$cluster, color=TRUE, shade=TRUE, labels=0, lines=0, main = "CLUSTERING PLOT")
```
Observamos que hay claramente 3 grupos: rojo, rosa y azul. Se obseerva una superposición entre los clusters, principalmente el rojo y el rosa lo que nos quiere decir que los grupos no están perfectamente diferenciados y que puede haber patrones de comportamiento similares entre individuos de estos clusters.<br><br>

#### **4.12 Visualizamos el Coeficiente de Silueta <br><br>**
```{r}
library(factoextra)
fviz_silhouette(silhouette(clustering_result$cluster, dist(data_clustering)), main = "SILHOUETTE")
```
La mayoría de los puntos tienen valores mayores a 0.5, lo cual sugiere que el custering es aceptable. El cluster verde tiene los valores de silueta más altos indicando que los puntos están mejor definidos. El rojo presenta mayor variabilidad y el azul muestra una forma regular con valores medios.<br><br>

#### **4.13 Calculamos la matriz de distancias usando el método "canberra"<br><br>**
```{r}
dist_matrix <- dist(data_clustering, method = "canberra")
```

#### **4.14 Aplicamos el clustering jerárquico con el método "complete"<br><br>**
```{r}
hclust_result <- hclust(dist_matrix, method = "complete")
```
#### **4.15 Visualizamos el dendrograma <br><br>**
```{r}
plot(hclust_result, hang = -1, cex = 0.6, main = "DENDROGRAM: Canberra Distance")
```

#### **4.16 Procedemos a cortar el dendrograma:<br><br>**
```{r}
plot(hclust_result, hang = -1, cex = 0.6, main = "DENDROGRAM: Canberra Distance")
abline(h = 1.5, col = "red", lty = 2) 
```

Observamos claramente 3 clusters gracias al corte.Las ramas largas indican clusters bien separados y las cortas en la parte inferior muestran grupos muy pequeños y similares.<br><br>

#### **Conclusiones Generales sobre clustering **<br><br>

**Silhouette Plot:**<br><br>
Proporciona información sobre la cohesión y separación de los clusters generados por K-means.<br>
  Identifica qué clusters son más compactos y cuáles tienen mayor variabilidad.<br><br>
**Dendrograma (Canberra Distance):**<br><br>
Proviene del clustering jerárquico y muestra la estructura de los datos en forma de árbol. Nos permite identificar 3 clusters principales al cortar a la altura de 1.5.<br><br>
**Clustering Plot:**<br><br> 
  Este gráfico proyecta los clusters de K-means en dos componentes principales:
  Muestra cómo se distribuyen los puntos.<br><br>
  Expone la superposición entre los clusters rojo y azul, lo que sugiere similitudes en las  variables utilizadas (BMI, FAVC y FCVC).<br><br>

#### **Cómo se Relacionan los Tres Gráficos**<br><br> 
**Silhouette Plot:**<br><br>
  Nos dice que el cluster verde es el más cohesivo (mejor agrupado).<br>
  Los clusters rojo y azul tienen mayor variabilidad, lo que indica posibles solapamientos.<br><br>
**Dendrograma:**<br><br>
  Muestra la estructura jerárquica de los datos.<br>
  Al cortar a 1.5, se observan claramente 3 clusters principales, lo cual confirma el número de clusters sugerido por el Método del Codo en K-means.<br><br>
**Clustering Plot:**<br><br>
  Visualmente, muestra los clusters rojo, verde y azul proyectados en dos dimensiones.
  La superposición entre rojo y azul refuerza que estas dos agrupaciones tienen características similares.<br>

#### **Conclusión General Integrada**<br><br>
#### **Los tres gráficos se complementan y nos permiten llegar a una conclusión más sólida:** <br><br>
  #Cluster Verde:Representa a las personas con mejores hábitos (alto consumo de vegetales, menor BMI, menor consumo calórico).<br>
   #Confirmado por la alta cohesión en el Silhouette Plot y la visualización clara en el Clustering Plot.<br>
  #Clusters Rojo y Azul:Representan a las personas con mayor riesgo de obesidad o sobrepeso:<br>
   #FAVC frecuente (alta ingesta calórica).<br>
   #FCVC bajo a moderado (bajo consumo de vegetales).<br>
   #BMI elevado.<br>
   #Estos grupos tienen superposición, como se ve en el Clustering Plot, lo que indica similitudes en sus comportamientos.<br>
  #Consistencia del Número de Clusters:Tanto el Silhouette Plot como el Dendrograma confirman que 3 clusters es una segmentación adecuada.<br>


## **Conclusiones del Trabajo.**<br><br>

Es evidente la importancia que tiene la recolección, preprocesamiento y procesamiento de los datos para desarrollar cualquier proyecto análisis de datos o aprendizaje automático entre otros, siempre debemos procurar asegurar que estamos seleccionando datos de calidad, altamente confiables y relevantes para el tema que deseamos resolver. <br>
Según el conjunto de datos o variables que seleccionemos en esos primeros pasos del análisis de la información, nos abrirá el camino para garantizar el modelado de datos correcto, que técnicas de aprendizaje supervisado o no supervisado aplicar así como sus métricas de desempeño que garantice que nuestras variables de estudio tengan una respuesta lo más precisa y confiable posible.<br>
 
